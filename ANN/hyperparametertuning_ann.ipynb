{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN) \n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  -    The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  -  A common practice is to start with 1-2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow (from -r requirements.txt (line 1))\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (1.4.2)\n",
      "Collecting tensorboard (from -r requirements.txt (line 5))\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: streamlit in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (1.32.0)\n",
      "Collecting scikeras (from -r requirements.txt (line 8))\n",
      "  Using cached scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (25.9.23)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (6.30.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.76.0)\n",
      "Collecting keras>=3.10.0 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (3.11.0)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard->-r requirements.txt (line 5)) (11.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 5))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from tensorboard->-r requirements.txt (line 5)) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from streamlit->-r requirements.txt (line 7)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from streamlit->-r requirements.txt (line 7)) (8.3.0)\n",
      "Collecting numpy (from -r requirements.txt (line 3))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting packaging (from tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow (from tensorboard->-r requirements.txt (line 5))\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "INFO: pip is looking at multiple versions of streamlit to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting streamlit (from -r requirements.txt (line 7))\n",
      "  Using cached streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pyarrow<22,>=7.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (19.0.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from streamlit->-r requirements.txt (line 7)) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (4.0.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 7)) (0.8.0)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from streamlit->-r requirements.txt (line 7)) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (4.25.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 1)) (0.43.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7)) (4.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 1)) (14.2.0)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow->-r requirements.txt (line 1))\n",
      "  Using cached optree-0.18.0-cp312-cp312-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\saisr\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.28.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 1)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\saisr\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 1)) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.5 MB 11.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/15.5 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.5 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.1/15.5 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.5 MB 8.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.8/15.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 8.2 MB/s eta 0:00:00\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp312-cp312-win_amd64.whl (212 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp312-cp312-win_amd64.whl (312 kB)\n",
      "Installing collected packages: namex, libclang, termcolor, tensorboard-data-server, optree, opt_einsum, numpy, google_pasta, gast, astunparse, absl-py, tensorboard, ml_dtypes, keras, tensorflow, scikeras, streamlit\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: streamlit\n",
      "    Found existing installation: streamlit 1.32.0\n",
      "    Uninstalling streamlit-1.32.0:\n",
      "      Successfully uninstalled streamlit-1.32.0\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 gast-0.6.0 google_pasta-0.2.0 keras-3.12.0 libclang-18.1.1 ml_dtypes-0.5.4 namex-0.1.0 numpy-1.26.4 opt_einsum-3.4.0 optree-0.18.0 scikeras-0.13.0 streamlit-1.51.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.3.2 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.2.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\saisr\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\saisr\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\saisr\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\saisr\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\saisr\\AppData\\Local\\Temp\\ipykernel_26600\\1921198388.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\saisr\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\saisr\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\saisr\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     43\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     46\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, LabelEncoder, OneHotEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     51\u001b[39m     ArrowDtype,\n\u001b[32m     52\u001b[39m     Int8Dtype,\n\u001b[32m     53\u001b[39m     Int16Dtype,\n\u001b[32m     54\u001b[39m     Int32Dtype,\n\u001b[32m     55\u001b[39m     Int64Dtype,\n\u001b[32m     56\u001b[39m     UInt8Dtype,\n\u001b[32m     57\u001b[39m     UInt16Dtype,\n\u001b[32m     58\u001b[39m     UInt32Dtype,\n\u001b[32m     59\u001b[39m     UInt64Dtype,\n\u001b[32m     60\u001b[39m     Float32Dtype,\n\u001b[32m     61\u001b[39m     Float64Dtype,\n\u001b[32m     62\u001b[39m     CategoricalDtype,\n\u001b[32m     63\u001b[39m     PeriodDtype,\n\u001b[32m     64\u001b[39m     IntervalDtype,\n\u001b[32m     65\u001b[39m     DatetimeTZDtype,\n\u001b[32m     66\u001b[39m     StringDtype,\n\u001b[32m     67\u001b[39m     BooleanDtype,\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     69\u001b[39m     NA,\n\u001b[32m     70\u001b[39m     isna,\n\u001b[32m     71\u001b[39m     isnull,\n\u001b[32m     72\u001b[39m     notna,\n\u001b[32m     73\u001b[39m     notnull,\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     75\u001b[39m     Index,\n\u001b[32m     76\u001b[39m     CategoricalIndex,\n\u001b[32m     77\u001b[39m     RangeIndex,\n\u001b[32m     78\u001b[39m     MultiIndex,\n\u001b[32m     79\u001b[39m     IntervalIndex,\n\u001b[32m     80\u001b[39m     TimedeltaIndex,\n\u001b[32m     81\u001b[39m     DatetimeIndex,\n\u001b[32m     82\u001b[39m     PeriodIndex,\n\u001b[32m     83\u001b[39m     IndexSlice,\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     85\u001b[39m     NaT,\n\u001b[32m     86\u001b[39m     Period,\n\u001b[32m     87\u001b[39m     period_range,\n\u001b[32m     88\u001b[39m     Timedelta,\n\u001b[32m     89\u001b[39m     timedelta_range,\n\u001b[32m     90\u001b[39m     Timestamp,\n\u001b[32m     91\u001b[39m     date_range,\n\u001b[32m     92\u001b[39m     bdate_range,\n\u001b[32m     93\u001b[39m     Interval,\n\u001b[32m     94\u001b[39m     interval_range,\n\u001b[32m     95\u001b[39m     DateOffset,\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m     97\u001b[39m     to_numeric,\n\u001b[32m     98\u001b[39m     to_datetime,\n\u001b[32m     99\u001b[39m     to_timedelta,\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    101\u001b[39m     Flags,\n\u001b[32m    102\u001b[39m     Grouper,\n\u001b[32m    103\u001b[39m     factorize,\n\u001b[32m    104\u001b[39m     unique,\n\u001b[32m    105\u001b[39m     value_counts,\n\u001b[32m    106\u001b[39m     NamedAgg,\n\u001b[32m    107\u001b[39m     array,\n\u001b[32m    108\u001b[39m     Categorical,\n\u001b[32m    109\u001b[39m     set_eng_float_format,\n\u001b[32m    110\u001b[39m     Series,\n\u001b[32m    111\u001b[39m     DataFrame,\n\u001b[32m    112\u001b[39m )\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NaT,\n\u001b[32m      3\u001b[39m     Period,\n\u001b[32m      4\u001b[39m     Timedelta,\n\u001b[32m      5\u001b[39m     Timestamp,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     ArrowDtype,\n\u001b[32m     11\u001b[39m     CategoricalDtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     PeriodDtype,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     NaT,\n\u001b[32m     21\u001b[39m     NaTType,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     iNaT,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to create the model and try different parameters(KerasClassifier)\n",
    "\n",
    "def create_model(neurons=32,layers=1):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(neurons,activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Keras classifier\n",
    "model=KerasClassifier(layers=1,neurons=32,build_fn=create_model,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2],\n",
    "    'epochs': [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3,verbose=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
